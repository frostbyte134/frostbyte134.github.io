---
layout: post
title:  "SSD: Simgle Shot Multibox Detector"
date:   2019-09-12 08:00:05 +0800
categories: deep_learning
use_math: true
tags: deep_learning ssd detection need_revise
---

Revision history
* written in 2018-07-14
* revised in 2019-09-12

ECCV 2016, <a href="https://arxiv.org/abs/1512.02325" target="_blank">https://arxiv.org/abs/1512.02325</a>  

* Single cell (among \\(M\times N\\) feature map) of each feature maps, over the basenet represents a `bounding box` prediction
* Each layer of feature map over the basenet uses different sized basenet feature map
* not good at detecting small objs \\(\rightarrow\\) "zoom-in" sampling, with doubled training time  
\\(\leadsto\\) <a href="https://www.slideshare.net/ssuser06e0c5/focal-loss-detection-classification" target="_blank">Focal Loss and Retina net?</a>
* in regression perspective, the state space is over the (center points of each default boxes) and (w, h of each default boxes).


### Abstract, introduction


Current SOTA object detection systems with `explicit region prooposals and pooling` do
1. hypothesize bounding boxes
2. resample pixels or features for each box, and
3. apply a high-quallity classifier for all proposals.

Although accurate, this approach is somewhat slow.

Whereas, `SSD` _does not resample pixels or features for bounding box hypotheses_, eliminating bounding box proposals and the subsequent pixel or feature resampling stage (it handles all ROI at once, with multiple feature maps).  

Its contributions are,
* the core of `SSD` is predicting category scores and box offsets for a fixed set of default bnding boxes (at once), using __small convolutional filters(3x3)__ applied to feature maps.
* for high detection accuracy, `SSD` produces prediction of different scales from feature maps of different scales, and explicitly separate predictions by aspect ratio (using separate __predictors (filters)__ for different aspect ratio detections).

### Model
* Over the base net, there are __several convolutional layers__, which are used to find a most probable default box.  
* Each convolutional layer corresponds to __different scale__ of default boxes (default boxes in a same layer have same scale). However the receptive field of the conv layer element must not match (the receptive field must be larger?) with the box size.

Reason for using multiple size of feature maps 
* <a href="#10">[10]</a>, <a href="#11">[11]</a> - low lvl features maps can improve semantic segmentation quality, b/c they have more details about the input objs.
* <a href="#12">[12]</a> - adding global context pooled from a feature map can help smooth the segmentation results

Default boxes are deployed in grid-fassion, and for each (assigned) feature map mlocation there exists 6 different aspect ratios (their sizes are all equivalent though). For details refer to the paper.  
Scales are also uniformly distributed. 1 scale for each feature map.





### Default box
* The __basic element__ for predicting parameters of a potential detection  
= \\(3\times3\\) small kernel ("SAME" conv)
* One output feature spatial location  \\(\leftrightarrow\\)  a set of \\(k\\)(=6 or 5 in the paper) default boxes


For single box, we have \\[4+c\\] logits where
* \\(4\\) - offsets relative to the original default box shape
* \\(c\\) - number of classes. corresponds to a logit for each class in the box area) parameters.  

Thus,
1. assuming \\((N\times M)\times p\\) input feature map,
2. we have (3by3) conv2d \\((p\rightarrow k(c+4))\\) with filter weights \\((3\times3\times p)\times (k\times (4+c)\\), and
3. \\((M\times N)\times k(4+c)\\) output feature map.

\\(\rightarrow\\) A \\(N\times M\\) square conv layer output over the basenet is convolved with \\(3\times3\\) filters, to predict \\(n\times n\times k\\) default boxes with (similar) scales and different aspect ratios?

In SSD, for a ground truth box we can assign multiple default boxes.
<hr/>
#### Matching strategies
* As in <a href="#7">Multibox</a>, match each gt box to the default box with the best IOU
* Unlike <a href="#7">Multibox</a>, then match default boxes to any gt box witgh IOU over than 0.5

\\(\rightarrow\\) this __simplifies the learning problem__, allowing the network to predict high scores for multiple overlapping default boxes, rather than requiring it to pick only the one with maximum overlap.

### Tiling of Default Boxes
1. `scale`\\(s_k\\):  
Suppose we have \\(m\\) feature maps above the base net, for prediction. The scale of default boxes for each fet map is
\\[s\_k=s\_\{min\}+\frac\{s\_\{max\}-s\_\{min\}\}\{m-1\}(k-1),\quad k\in[1,m]\\]
where \\(s_\{min\}=0.2 (0.1?),\\>s_\{max\}=0.9\\), so that \\(s_k\\) is discrete uniform in \\([s\_\{min\},s\_\{max\}]\\)
2. `aspect ratios` :\\[a_r=\\{1,2,3,\frac\{1\}\{2\},\frac\{1\}\{3\}\\}\\]
We can compute the width \\(w_k^a=s_k\sqrt\{a_r\}\\) and height \\(h_k^a=s_k/\sqrt\{a_r\}\\). For \\(a_r=1\\), we add one more scale \\(s_k'=\sqrt\{s_ks_\{k+1\}\}\\), __resulting 6 default boxes per featur map location.__
3. `Center of default box`:\\[\left(\frac\{i+0.5\}\{\|f_k\|\},\frac\{j+0.5\}\{\|f_k\|\}\right)\\]where \\(\|f_k\|\\) is the size of \\(k\\)-th convolutional feture mapo, \\(i,j\in[0,\|f_k\|]\\).

All of the distances here is a __relative distance__ wrt input image size (Can it be larger than input image is still a question. Maybe i can figure it out in pytorch codes)

### Training Objective
Let \\(x\_\{ij\}^p=\\{1,0\\}\\) be an indicator function, for matching the \\(i\\)-th default box to the \\(j\\)-th gt box of category \\(p\\). In above matching stratefy, we can have \\(\sum\_ix_\{ij\}^p\geq1\\) (for a single GT box, there could be many default boxes assigned to it).

The __objective loss__ \\[L(x,c,l,g)=\frac\{1\}\{N\}(L\_\{conf\}(x,c)+\alpha L_\{loc\}(x,l,g)),
\quad N=\text\{# of matched default boxes\}\\] is a weighted sum of the `localization los` (loc):
\\[L_\{loc\}(x,l,g)=\sum\_\{i\in Pos,\}^\{N\}\sum\_\{m\in \\{cx,cy,w,h\\}\}\text\{smooth\}\_\{L1\}(l_i^m-\hat\{g\}\_j^m)\\]
where
* \\(\{Pos\}\\): number of positive default boxes (which having mathcing GT box)
* \\(l\\): predicted box, \\(g\\): gt box, \\(d\\): default box (Note that we have 3 types of box)
* \\(cx,\\>cy\\): center of the box.  
* \\(l\_i^\{cx\}\\) is the __value added to the default box__ center x coordinate \\(d\_i^\{cx\}\\), so that the final prediction is \\[l\_i^\{cx\}d\_i^w + d\_i^\{cx\}d\_i^\{w\}\\]
* \\(w,\\>h\\): width, height of the box
\\[\hat\{g\}\_j^\{cx\}=(g\_j^\{cx\}-d\_i^\{cx\})/d\_i^w,
\quad\quad\hat\{g\}\_j^\{cy\}=(g\_j^\{cy\}-d\_i^\{cy\})/d\_i^h,
\quad\quad\hat\{g\}\_j^\{w\}=\log\left(\frac\{g\_j^w\}\{d\_i^w\}\right),
\quad\quad\hat\{g\}\_j^\{h\}=\log\left(\frac\{g\_j^h\}\{d\_i^h\}\right)\\]
(Then, the loss becomes 0 when \\[g_i^m=l_i^m\\]
For example, for \\(cx\\), 
\\[g_i^\{cx\}=l_i^\{cx\}\quad\rightarrow\quad (g\_j^\{cx\}-d\_i^\{cx\})/d\_i^w=l\_i^\{cx\}\\]
\\[g\_i^{cx\}=l\_i^\{cx\}d\_i^w + d\_i^\{cx\}d\_i^\{w\}.\\]
By dividing with \\(d\_i^w\\) or \\(d\_i^h\\), we give some advantage to the distance of small boxes. If small and large box have same offset, offset of small boxes get more weight)

and the `confidence loss` (conf), is standard softmax loss (cross entropy with one-shot discrete distribution) with \\(c\\) as _class confidence_ (logit):
\\[L\_\{conf\}(x,c)=-\sum\_\{i\in Pos\}^N\sum\_jx\_\{ij\}\log(\hat\{c\}_i^p)-\sum\_\{i\in Neg\}\log(\hat\{c\}_i^p)\quad\text\{where\}\quad \hat\{c\}_i^0=\frac\{\exp(c_i^p)\}\{\sum\_p\exp(c_i^p)\}\\]
(left - for a positive default box, let its gt box (which makes it positive) be \\(j\\), with class \\(p\\). Other \\(\hat\{c\}_i^\{p'\}\\)s are 0, and we want to maximize above property)

#### Hard negative mining
* a training example is a pair
\\[\text\{\{GT box, predicted box\}\}\\]
and a `negative example` refers to a pair where the matching does not set for predicted box (remember that, there is always a matching pair for each GT box). 
* When the default boxes are too many, there is an imbalance between positive / negative training examples. 
* Instead of using all negative examples, we sort them using the highest confidence loss, and use some of them so that the ratio of (positive / negative) becomes 1:3.  
(used negative examples, which the network is confident on classification)


### Augmentation
refer to the paper.

TODO:
1. training on pascal-voc or COCO and reconstructing performance

Links:  
<a href="https://arxiv.org/pdf/1512.02325.pdf" target="_blank">SSD: Single Shot MultiBox Detector</a>  
<a href="https://arxiv.org/abs/1411.4038" target="_blank" id="7">[7] (Multibox) Scalable object detection using deep neural networks. In: CVPR. (2014)</a>  
<a href="https://arxiv.org/abs/1411.4038" target="_blank" id="10">[10] Fully Convolutional Networks for Semantic Segmentation</a>  
<a href="https://arxiv.org/abs/1411.5752" target="_blank" id="11">[11] Hypercolumns for object segmentation and fine-grained localization. In: CVPR. (2015)</a>  
<a href="https://arxiv.org/abs/1506.04579" target="_blank" id="12">[12] ParseNet: Looking wider to see better. In: ILCR. (2016)</a>  
