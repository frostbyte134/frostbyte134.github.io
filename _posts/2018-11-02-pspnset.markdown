---
layout: post
title:  "PSPNet"
date:   2018-11-01 09:00:05 +0800
categories: deep_learning
use_math: true
tags: deep_learning segmentation psp
---

PASCAL VOC 2012 test mIOU 85.4


### Abstract
* ... we exploit the capability of global context information by different-region-based context aggregation through our __pyramid pooling module__ together with the proposed __pyramid scene parsing network__ (`PSPNet`)

### Introduction
> But viewing the image regarding the context prior that the scene is described as boathouse near a river, correct prediction should be yielded.

* found that the major issue for current FCN-based models is lack of suitable strategy to utilize global scene category clues (No mention how they found it)
* In addition to traditional dilated FCN for pixel prediction, we extend the pixel-lvl feature to the specially designed global pyramid pooling one.
* ... proposed an optimization strategy with depply supervised loss. (aux head with weights (hyperparam))

### Related work

1. To enlarge the receptive field of neurla networks, methods of [3, 40] used dilated convolution.
2. Noh et al proposed a coarse-to-fine structure with deconv network to learn the segmentation mask.(link)  
> Our baseline network is FCN and dilated network.

Other work mainly proceeds in two directions.
1. One line is with multi-scale feature ensembling. Since in deep networks, hugher-layer feature contains more semantic meaning and less location information. Combining multi-scale features can improve the performance.
2. The other direction is based on structure prediction. CRF. ... Yet there is still much room to exploit necessary information in complex scenes.

Liu et al. [24] proved that global avg pooling with FCN can improve semantic segmentation results. However, our experiments show that these global descriptors are not representative enough for the challenging data.  
Therefore, different from global pooling above, we exploit the capability of global context info by different-region-based context aggegation via our pyramid scene parsing network.

### Important observations

1. context relationship is universal and important especially for complex scene understanding.
2. ... many class label pairs in the ADE20K dataset that are confusing in classification. (skyscraper vs building, example in the paper)... This problem can be remedied by utilizing the relationship between categories.
3. Inconspicuous class  
	* small size things - hard to find
	* too big - discontinuity due to restricted size of receptive fields.  
	> To improve performance for remarkably small or large objects, one should pay attention to different sub-regions that contain inconspicuous-category stuff. (sub region = a spacial location of largely pooled feature map?)

To summarize these observations, many errors are partially or completely related to contextual relationship and global information for different receptive fields. Thus a deep network with a suitable global-scene-level prior can much improve the performance of scene parsing.
	

	
### Pyramid Pooling Module
> In a DNN, the size of receptive field can roughly indicates how much we use context information.

Although theoretically, the receptive field of ResNet is already larger than the input image, it is shown by __Zhou et al. [41]__ that the __empirical receptive field of CNN is much smaller than the theroretical one eespecially on high-lvl layers.__  
This makes many networks not sufficiently incorporate the momentous golbal scenary prior. We address this issue by proposing an effective global prior representation.

Global avg pooling is a good baseline model as the global contextural prior, which is commonly used in image classification tasks. (Link the CAM paper). But regarding the complex scene images, pixels in these images are annotated regarding many stuff and objects. Directly fusing them to form a single vector may lose the spatial relation and cause ambiguity. Gobal contet information along with sub-region context is helpful in this regard to distinguish among various categories. A more powerful representation could be fused information from different sub-regions with these receptive fields. Similar conclusion was drawn in classical work of scene/image classification [18, 12(SPP)].

In [12] (SPP), feature maps in different levels generated by pyramid pooling were finally flattened and concateneted to be fed into a fc layer for classification. THis global prior is designed to remove the fixed size constraint. To further reduce contextinfo loss between different sub-regions, we propose a hierarchical golbal prior, containing info with different scales and varying among different sub-regions.

<img src="{{ site.url }}/images/deeplearning/psp.png" class="center" style="width:1000px"/>  
Here, 4 refers to len([1, 2, 3, 6]).  
Instead of 1/4 1by1 conv, we can
1. upsample the pooled feature map to (w, c).
2. concat them
3. Perform (w, h, 5c) \\(\rightarrow\\) (w, h, c) 1by1 conv (as in <a href="https://github.com/Lextal/pspnet-pytorch/blob/master/pspnet.py" target="_blank">github source code</a> of someone)

... the multi-stage kernels should (of pooling) should maintain a reasonable gap in representation. Our pyramid pooling module is a four-lvl one with bin sizes of 1by1, 2by2, 3by3 and 6by6 respectively.


### Network Details
1. Basenet = (dilated) Resnet 50, 101
2. bs = 16, os = 8
3. Aux head (handling opt difficulty): at resnet4b22 (layer4[-1]), weight 0.4
4. lr = 0.001, wd = 0.0001, momentum = 0.9
5. Poly learning rate = \\[\left(1-\frac\{\text\{iter\}\}\{\text\{maxiter\}\}\right)^\{\text\{power\}\}\\]
	* maxIter = 30K for VOC, 90K for Citys
	* power = 0.9
6. Preproc:
	* random mirrir
	* random resize bet 0.5 and 2
	* random rotation [-10, 10]
	* random Gaussian blur (for Imagenet and PASCAL only!)
	

	
<a href="https://github.com/hszhao/PSPNet" target="_blank">Author github</a>
* PSPNet50 on ADE20K valset (mIoU/pAcc): 41.68/80.04 (ss) and 42.78/80.76 (ms)
* PSPNet101 on VOC2012 testset (mIoU): 85.41 (ms)
* PSPNet101 on cityscapes valset (mIoU/pAcc): 79.70/96.38 (ss) and 80.91/96.59 (ms)

### Cityscapes-Author
<a href="https://github.com/hszhao/PSPNet" target="_blank">Author github</a>

crop size 713, base_size(?): 2048, step=125 (500/4?)

Val set
* 79.70


Test set
* paper = 80.2
* <a href="https://www.cityscapes-dataset.com/detailed-results/" target="_blank">leaderboard</a> = 81.2

### Cityscapes-holyseven
<a href="https://github.com/holyseven/PSPNet-TF-Reproduce" target="_blank">github link</a>

* Tensorflow

<table>
   <tr>
      <td></td>
      <td>Backbones</td>
      <td>L2</td>
      <td>L2-SP</td>
   </tr>
   <tr>
      <td rowspan="2">Cityscapes (train set: 3K)</td>
      <td>ResNet-50</td>
      <td>76.9/?</td>
      <td>77.9/?</td>
   </tr>
   <tr>
      <td>ResNet-101</td>
      <td>77.9/?</td>
      <td>78.6/?</td>
   </tr>
   <tr>
      <td rowspan="2">Cityscapes (coarse + train set: 20K + 3K)</td>
      <td>ResNet-50</td>
      <td></td>
      <td></td>
   </tr>
   <tr>
      <td>ResNet-101</td>
      <td>80.0/80.9</td>
      <td>80.1/81.2*</td>
   </tr>
   <tr>
      <td rowspan="2">SBD </td>
      <td>ResNet-50</td>
      <td>76.5/?</td>
      <td>76.6/?</td>
   </tr>
   <tr>
      <td>ResNet-101</td>
      <td>77.5/79.2</td>
      <td>78.5/79.9</td>
   </tr>
   <tr>
      <td rowspan="2">ADE20K</td>
      <td>ResNet-50</td>
      <td>41.81/?</td>
      <td></td>
   </tr>
   <tr>
      <td>ResNet-101</td>
      <td></td>
      <td></td>
   </tr>
</table>

*This model gets 80.3 without post-processing methods on [Cityscapes test set (1525)](https://www.cityscapes-dataset.com/method-details/?submissionID=1148).

resnet-50 on Cityscapes, getting around 77.9
* img_size = 816
* lr=0.0001, weight_decay_rate 0.0001 / 0.001
* bs=4, gpus=4
* --random_rotate=0 ????

__mirror on val set__: add logits from mirrored image?

### Cityscapes-hellochick
<a href="https://github.com/hellochick/PSPNet-tensorflow" target="_blank">github link</a>

* Tensorflow, simply converted weights

city val set (With SS: )
* Without flip	76.99%
* Flip	77.23%

val params
* crop=7120
* steps=500

### Reproduction result
- 77.75 with resnet50, coarse data only

Cityscapes val images  

<img src="{{ site.url }}/images/deeplearning/pspnet/img_frankfurt_000001_043395_valImg.png" class="center" style="width:1000px"/>  

<img src="{{ site.url }}/images/deeplearning/pspnet/img_frankfurt_000001_080091_valImg.png" class="center" style="width:1000px"/>

Images from the younin city  

<img src="{{ site.url }}/images/deeplearning/pspnet/img_yongin_000000_00000_valImg.png" class="center" style="width:1000px"/>

<img src="{{ site.url }}/images/deeplearning/pspnet/img_yongin_000000_00001_valImg.png" class="center" style="width:1000px"/>

<img src="{{ site.url }}/images/deeplearning/pspnet/img_yongin_000000_00002_valImg.png" class="center" style="width:1000px"/>


Images from the internet  
<img src="{{ site.url }}/images/deeplearning/pspnet/img_yongin_000000_00005_valImg.png" class="center" style="width:1000px"/>

[22]
Next:  