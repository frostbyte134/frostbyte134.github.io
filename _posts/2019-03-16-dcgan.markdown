---
layout: post
title:  "DCGAN - Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"
date:   2019-03-16 08:00:05 +0800
categories: deep_learning
use_math: true
tags: deep_learning gan dcgan
---

<a href="https://arxiv.org/abs/1511.06434" target="_blank">https://arxiv.org/abs/1511.06434</a>



### Abstract, Intro
* we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator
* `GAN`s provide an attractive alternative to maximum likelihood techniques.
* In this paper, we make the following contributions
	* We propose and evaluate a set of constrains on the architectural topology of convolutional GANs that make them stable to train in most settings. We name this class of architectures Depp Convolutional GANs (DCGAN)
	* We visualize the filters learnt by GANs and empirically show that specific filters have learned to draw specific objects.

### Related works
Similarly, using a gradient descent on the inputs let us inspect the ideal image that activates certain subsets of filters (<a href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" target="_blank">Mordvintsev et al.</a>)

### Approach and Model Architecture
Core to our approach is adopting and modifying three recently demonstrated changes to CNN architectures
1. __all-conv net__ (Springenberg et al) which replaces deterministic spatial pooling functions with strided convolutions, allowing the network to learn its own spatial downsampling.
2. trend towards __eliminating fc layers__ on top of conv features. EX) - global average pooling on top of the model. _We found GAP increased model stability but hurt convergence speed._ A middle ground of directly connecting the highest convolutional features to the input and output respectively of the generator and discriminator worled well.
3. __Batch normalization__. Ths alleviates poor initialization and helps gradient flow in depeer models. _Directly applying batchnorm to all layers however, resulted in sample oscillation and model instability_. This was avoided by not applying batchnorm to the G ouput layer and the D input layer.
4. Leaky relu (0.2)

> Architectural guidlines for stable Deep Convolutional GANs  
	1. replace any pooling layers with strided convs(D) and fractional-strided convs(G)  
	2. Use batch norm in both the G and the D  
	3. Remove fc hidden layers for deeper architectures.  
	4. use relu activation in generator for all layers ecept for the output, which uses Tanh  
	5. Use LeakyRelu activation in the D for all layers.  

### Details of Adversarial Training
bs=128, LeakyReLU(0.2), init=N(0, 0.02), ADAM(lr=0.0002, \\(\beta\_1=0.5\\))

### Empirical Validation
Trained G and D __on imagenet-1k__, and used D as the feature extractor of classifier (add fc on top) on __CIFAR-10__. (DCGAN + L2-SVM - 82.8)

### Visualizing Internals  
we __do not do__ any kind of `nereast neighbor searching` on the training set. Nearest neighbors in pixel of feature space are trivially folled (Thesis et al., 2015) by small image transforms.  

1. Walking in the Latent space  
	- visualization with continuously varying \\(z\\)
2. Visualizing the discriminator features  
	- using guided bp as proposed by (Springenberg et al), we show in Fig.5 that the features learnt by the D activate on typical parts of a bedroom, like beds and windows.
3. vector arithmatic on Face samples  
	vector("King") - vector("Man") + vector("Woman") resulted in a vector whose nearest neighbor was the vector for Queen.
