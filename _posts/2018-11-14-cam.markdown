---
layout: post
title:  "(CAM) Learning Deep Features for Discriminative Localization"
date:   2018-11-14 09:00:05 +0800
categories: deep_learning
use_math: true
tags: deep_learning basenet
---

<a href="https://arxiv.org/abs/1512.04150" target="_blank">https://arxiv.org/abs/1512.04150</a>


### GMP vs GAP
GAP is better for the localization (?)

1. GMP
	* encourages the net to identify just one discriminative part
	* low scores for all image regions except the most discriminative one do not impact the score as you just perform a max op.
2. GAP
	* loss (or the weight multiplied to the avg pool output) for AVG pooling benefits when the network identifies all discriminative regions of an object as compared to max pooling
	* the value of map can be maximized by finding all discriminative parts of an object as alllow activations reduce the output



### CAM
We use `class activation map` to refer to the weighted activation maps generated for each image.

1. Consider the final feature map \\(f\_c(x,y)\\) of size \\(W\times H \times C\\). For channel \\(c\\), `GAP` performs avg pooling by
\\[F^c=\sum\_\{x,y\}f\_c(x,y)\\]
2. For the output of GAP \\(1\times 1\times C\\), we generally perform fc (or 1by1 conv). The logit \\(S\_k\\) of class \\(k\\) can be calculated by
\\[S\_k=\sum\_\{c\}w\_\{c\}^kF^c\\]
where \\(w\_\{c\}^k\\) corresponds to the weight of channel \\(c\\) wrt class \\(k\\).
3. Unraveling the equation gives new formulation.
\\[S\_k=\sum\_\{c\}w\_\{c\}^k\sum\_\{x,y\}f\_c(x,y)\\]
\\[=\sum\_\{x,y\}\sum\_\{c\}w\_\{c\}^kf\_c(x,y)\\]
We define class activation map on \\((x,y)\\), \\(M\_k(x,y)\\) 
\\[M\_k(x,y):=\sum\_\{c\}w\_\{c\}^kf\_c(x,y)\\]
as the localization score of the network, how the network reacts to the pixel value in \\((x,y)\\).  
By simply upsampling the CAM to the size of the input image, we can identify the iamge regions most relevant to the particular category.


[22]
Next:  


