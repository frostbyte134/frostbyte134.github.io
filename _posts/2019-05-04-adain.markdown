---
layout: post
title:  "(AdaIN) Arbitrary Stye Transfer in Real-time with Adaptive Instance Normalization"
date:   2019-05-04 09:00:05 +0800
categories: deep_learning
use_math: true
tags: deep_learning conditional_gan generative batch_normailziation instance_normalization
---

<a href="https://arxiv.org/abs/1703.06868" target="_blank">https://arxiv.org/abs/1703.06868</a>

> __AdaIN__ performs style transfer in the feature space by transferring feature statistics, specifically the channel-wise mean (which encodes more direct style info) and variance (more subtle style info).

Preliminaries:
* ... <a href="{{site.url}}/deep_learning/2019/05/04/adain.html" target="_blank">a novel adaptive instance normalization (`AdaIN`)</a>
* PG-GAN
* BigGAN

Contributions
* Latent codes are fed into network only through the `AdaIN`, not to the input
* noise for each layer - like `BigGAN`

### Abstract
* ... <a href="{{site.url}}/deep_learning/2019/05/04/adain.html" target="_blank">a novel adaptive instance normalization (`AdaIN`)</a> layer that aligns the mean and variance of the content features with those of the style features.
* ... without the restriction to a pre-defined set of styles

### Introduction
* Gatys et al
  * DNN encodes not only the contents but also the style information
  * image style and contents are somewhat separable

> We propose a new interpretation that instance normalization performs style normalization by normalizing __feature statistics__, which have been found to carry the style information of an image [16, 30, 33]

* `AdaIN` simply adjusts the mean and variance of the content input to match those of the style input.

### Related work
`Style transfer`
* Some early approaches include histogram matching on linear filter responses and non-parametric smapleing. Those methods typically rely on lov-lvl statistics and often fail to caputure semantic structures.

__Gatys et al__
* style transfer using DNN, by matching feature statistics in convolutional layers of a DNN.
* slow optimization process, that iteratively updates the image to minimize a content loss and a style loss computed by a loss network
* Common workaround - replace optimization with single-pass DNN

__Domoulin et al__
* Conditional BN
* 32 style and their interpolations

__which style loss function to use?__
* Gatys et al: 2nd-order statistics between feature activations, captured by the Gram matrix
* MRF loss, adversarial loss, histrogramloss, MMD loss, and _distance between channel-wise mean and variance_ are also used
* __Note__ that all the above loss functions aim to match some feature statistics between the style image and the synthesized image.

### Batch Normalization
\\[\text\{BN\}(x)=\gamma\left( \frac\{x-\mu(x)\}\{\sigma(x)\} \right) + \beta\\]
\\[\mu\_C=\frac\{1\}\{NHW\}\sum\_\{n=1\}^N\sum\_\{h=1\}^H\sum\_\{w=1\}^W x\_\{nchw\}\\]
\\[\sigma\_C=\sqrt\{\frac\{1\}\{NHW\}\sum\_\{n=1\}^N\sum\_\{h=1\}^H\sum\_\{w=1\}^W (x\_\{nchw\}-\mu\_c(x))^2+\epsilon\}\\]

* mini-batch stats during training 
* replace them with popular statistics during inference, introducing discrepancy between training/inference
* `Batch renormalization`: gradually use popular statistics during training (batchnorm2d in pytorch works the same)
* __Li et al__: BN can alleviate domain shifts by recomputing popular statistics in the target domain

From the `AdaIN` paper, section 3.4,
* ... (bn) can be intuitively understood as normalizing a batch of samples to be centered around a single style. Each single sample, however, may still have different style (even after the bn layer). This is undesirable when we want to transfer all imgs to the same style.
* Although the conv layers might learn to compensate the intra-batch style difference, it poses additional challenges for training.


### Instance normalization
<a href="{{site.url}}/deep_learning/2019/04/15/inst-norm.html" target="_blank">Ulyanov et al</a> found that significant improvement could be achieved simply by replacing BN layers with IN layers:
\\[\text\{IN\}(x)=\gamma\left( \frac\{x-\mu(x)\}\{\sigma(x)\} \right) + \beta\\]
\\[\mu\_\{NC\}=\frac\{1\}\{HW\}\sum\_\{h=1\}^H\sum\_\{w=1\}^W x\_\{nchw\}\\]
\\[\sigma\_\{NC\}=\sqrt\{\frac\{1\}\{HW\}\sum\_\{h=1\}^H\sum\_\{w=1\}^W (x\_\{nchw\}-\mu\_c(x))^2+\epsilon\}\\]


__IN layer are applied at test time unchanged__, whereas BN layers usually replace minbatch statistics with population statistics

* From the `AdaIN` paper, section 3.4,
> ... `IN` can normalize the style of each individual sample to the target style (not normalizing, since we have affine layer over BN). Training is facilitated b/c the rest of the net can focus on content manipulation while discarding the original style information.

### Conditional Instance Normalization
* embedding + per-class (style) affine parameters
\\[\text\{CIN\}(x)=\gamma^s\left( \frac\{x-\mu(x)\}\{\sigma(x)\} \right) + \beta^s\\]
* `CIN` requires \\(2FS\\) additional params, where \\(F\\): total # of feature maps in network, \\(S\\): num of styles
* Due to above, challenging to extent styles to more than thousands
* cannot adapt to arbitrary new styles without re-training the network

### Interpreting Instance Normalization
<a href="{{site.url}}/deep_learning/2019/04/15/inst-norm.html" target="_blank">Ulyanov et al</a> attribute the success of IN to its invariance ot the contrast of the content image.
* __However IN takes place in the feature space__, therefore it should have more profound impacts than a simple contrast normalization in the pixel space.
* Perhaps even more suprising is the fact that the affine params in IN can completely change the style of the output image.

It has been known that __convolutional feature stats can capture the style of an image__ [16, 30, 33]
* Li et al [33] recently showed that matching many other statistics, including channel-wise mean and var, are also effective for style transfer.
	> __Motivated by these observations__, we argue that IN performs a form of style normalization by normalizing feature stats, namely the mean and var.
* Although DNN serves as a image descriptor in [16, 33], we believe that the feature statstics of a \\(G\\) can also control the style of the generated image.

Experiments
* run IN/BN on training image, plot loss/iter
* run IN/BN on (constrast normalized images by performing histogram equalization on the luminance channel)  \\(\rightarrow\\) IN remain effective, showing that the explanation of <a href="{{site.url}}/deep_learning/2019/04/15/inst-norm.html" target="_blank">Ulyanov et al</a> is not suffice
* run IN/BN on style transfered img (using NN of [24])  
  \\(\rightarrow\\) IN becomes less effective


### AdaIN
If `IN` normalizes the input to a single style speficied by the affine params, is it possible to adapt it to arbitrarly given styles by using adaptive affine transformations?

`AdaIN` receives
* \\(x\\): content input
* \\(y\\): style input

and simply aligns the channel-wise mean and variance of \\(x\\) to match those of \\(y\\).

* No learnable params. Instead, it adaptively computes the affine params from the style input:
\\[\text\{AdaIN\}(x,y) = \sigma(y)\left( \frac\{x-\mu(x)\}\{\sigma(x)\} \right)+\mu(y)\\]



Next: 
* [33] (Demystifying neural network style transfer)?