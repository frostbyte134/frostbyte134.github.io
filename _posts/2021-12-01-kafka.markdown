---
layout: post
title:  "Kafka"
date:   2021-12-01 08:00:05 +0800
categories: coding
use_math: true
tags: coding
---

- <a href="https://aiokafka.readthedocs.io/en/stable/consumer.html" target="_blank">aiokafka 문서</a>
- <a href="https://medium.com/@jaykreps/exactly-once-support-in-apache-kafka-55e1fdd0a35f" target="_blank">exactly once in kafka (idempotent)</a>
- <a href="https://kafka.apache.org/documentation/#semantics" target="_blank">kafka semantics</a>

- <a href="https://www.thebookofjoel.com/python-kafka-consumers" target="_blank">이거 좋은듯</a>
    - <a href="https://jjaesang.github.io/kafka/2019/07/08/Exactly-Once-Semantics-kafka.html" target="_blank">참고?</a>


### Exactly once
https://medium.com/@jaykreps/exactly-once-support-in-apache-kafka-55e1fdd0a35f
- producer -> broker
    - 프로듀서는 (idempotent 옵션을 켰을 때) ack가 안오면 무지성 재전송하면 됨. 카프카에서 알아서 중복처리 해 줄 것 (이미 데이터가 들어온 오프셋이 오면 무시하는 듯)
- broker -> consumer. 사실 이부분이 힘듬
    1. `derived state`와 이 상태를 만드는데 쓰인 오프셋을 db에 트랜잭션으로 같이 저장 (!!)
    2. derived state과 offset을 멱등성있게 기록. 이것도 결국 derived state과 offset을 같이 저장하고, 더 낮은 offset의 update는 무시


https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/
- at least once: ack timeout시 재전송. 중복전송 가능성 있음
- at most once: ack timeout시 재전송안함
- exactly once: ack timeout시 재전송, 브로커단에서 중복처리 (멱등성!), 컨슈머도 커밋 잘
    - 처리되어야 하는 것들: 브로커 실패 (n이 replication factor일시 n-1 broker fail까진 괜찮음), 브로커단에서 중복전송 처리, 클라이언트단에서 derived state만큼 commit

브로커단에서의 멱등성 처리
- 시퀸스넘버를 가지고 처리됨 (replication log에 넘버 기록되어, 리더가 죽어도 새로 선출된 리더가 이어받아 처리)


#### Exactly Once, Kafka to Kafka
카프카에서 카프카로 데이터를 보낼 땐, Transaction을 활용 가능 - Producer의 Transaction context 안에 consumer의 commit까지 포함
 - 프로듀서에 컨슈머의 offset까지 (!) 커밋하는 <a href="https://towardsdatascience.com/exactly-once-semantics-across-multiple-kafka-instances-is-possible-20bf900c29cf" target="_blank">방식인 듯</a>

### Aiokafka

- Kafka maintains a numerical `offset` for each record in a partition
    - This offset acts as a __unique identifier of a record__ within that partition 
    - and also __denotes the position of the consumer in the partition__

There are actually two notions of position:
- The `position` gives the offset of the next record that should be given out. It will be one larger than the highest offset the consumer has seen in that partition. 
- The `committed position` is the last offset that has been stored securely. Should the process restart, this is the offset that the consumer will start from. The consumer can either automatically commit offsets periodically, or it can choose to control this committed position manually by calling `await consumer.commit()`.

> When using manual commit it is recommended to provide a `ConsumerRebalanceListener` which will process pending messages in the batch and commit before allowing rejoin. If your group will rebalance during processing commit will fail with `CommitFailedError`, as partitions may have been processed by other consumer already.`

- ConsumerRebalanceListener에 리밸런스시 flush / offset 저장 내용 구현 ㄱㄱ
    - 카프카가 group membership을 자동 조정할 때만 발생
    
> Note  
The committed offset should always be the offset of the next message that your application will read. Thus, when calling commit(offsets) you should add one to the offset of the last message processed.


#### group
__each partition is assigned to exactly one consumer in the group.__
- if there is a topic with four partitions and a consumer group with two processes, each process would consume from two partitions.
- 각 그룹별로 read offset을 따로 가져감 (highwater offset은 당연히 동일)
- 컨슈머는 regex로 등으로 현 그룹에서 원하는 토픽만 subscribe가능 / 매뉴얼 assignment가능


#### Transaction
- atomic이 아니고, 다수의 연산을 all or none으로 처리. 여러 파티션에 transaction하게 동시에 쓰는 것을 말하는 듯
- producer쪽에서 트랜잭션에 commit id를 설정 - consumer에서 commited message만 읽게 설정


### 카프카 데이터 플랫폼의 최강자 Chap 5
- 컨슈머의 주요 기능: 특정 파티션을 관리하고 있는 파티션 리더에게 메시지 가져오기 요청을 하는 것
    - 각 요청은 로그의 오프셋을 명시 -> 가져올 메시지의 위치를 조정가능 (받은 것 또 받을 수도 있음)
- `session.timeout.ms` (10초)
    - 브로커가 컨슈머가 살아있다고 판단하는 시간. 이 기간동안 하트비트를 (그룹 코디네이터)에게 보내지 않으면, 죽은 것으로 간주하고 `rebalancing` 수행
- 브로커는 컨슈머가 heartbeat에 응답해도, poll을 일정 주기로 안하면 끊어버림 (`max.poll.interval.ms`)
- 카프카의 순서 보장은 파티션 내에서만 됨
- 컨슈머 그룹: 여러 앱이 붙어서 따로 데이터를 땡길 수 있음. 컨슈머 그룹마다 오프셋을 따로 관리
- 리밸런싱: 컨슈머의 파티션에 대한 소유권이 이전하는 것
- 토픽에 파티션에는 하나의 컨슈머만 붙을 수 있음. 반대는 가능 (컨슈머 하나가 여러 파티션 땡기기)
- 커밋: 자동 / 수동 (로컬에서 처리하고 커밋 + sigterm handler로 k8s환경에서 손실을 최대한 줄일 수 있음)


trans
