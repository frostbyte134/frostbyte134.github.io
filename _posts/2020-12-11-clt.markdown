---
layout: post
title:  "Central Limit Theorem"
date:   2020-12-11 08:00:05 +0800
categories: probability
use_math: true
tags: math probability bayesian
---

TODO: add formal proof, after reviewing analysis

> <a href="https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-ii-inference-limit-theorems/" target="_blank">part-ii-inference-limit-theorems</a>

- <a href="https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/MITRES_6_012S18_Textbook.pdf" target="_blank">PDF</a>

### Different Views of the Sum of i.i.d RVs

Let \\(X\_1,...,X\_n\\) be i.i.d RVs, with finite \\(\mu, \sigma^2\\)

\\[S\_n := X\_1+...+X\_n\\]
- var = \\(n\sigma^2\\) is a function of \\(n\\), so diverges as \\(n\rightarrow\infty\\)
\\[M\_n = S\_n/n\\]
- var = \\(\sigma^2/n\\). converges to 0 as \\(n\rightarrow\infty\\). Not so informative
\\[\frac{S\_n}{\sqrt{n}}\\]
- var = \\(\frac{n\sigma^2}{n} = \sigma^2\\). Not a function of \\(n\\)
- distribution may change, but the variance stays constant as \\(n\rightarrow\infty\\). Will there be any limiting distribution?
- __BUT__
  1. we can divide by \\(\sigma\\) to make variance as 1
  2. If \\(E[X]\neq 0\\), then \\(E[\frac{S\_n}{\sqrt{n}}]\\) is a function of \\(n\\) which changes as \\(n\rightarrow\infty\\)
\\[Z\_n := \frac{S\_n-n\mu}{\sqrt{n}\sigma}\\)]
  - Now we have \\(E[Z\_n] = 0, V[Z\_n] = 1 (n\sigma^2/n\sigma^2)\\) 


### Central Limit Theorem

Let \\(Z\sim N(0, 1)\\)

> __Central Limit Theorem__ : \\(\forall\\ z,\quad \lim\_{n\rightarrow\infty}P(Z\_n\leq z) = P(Z\leq z)\\)

"Absolutely remarkable, highly nontrivial, and non-intuitive"

- universal, with respect to the distribution of \\(X\_i\\)
- only mean, variance matter
- There exists a _computational shortcut_ = N `colvolutions` (tedius)
- justification of the naturality of normal models. If the noises sources are many, iid RVs we can approximate their sum as a normal RV
- relies on the convergence of CDF
- generalization
  1. \\(X\_i\\) may not be identically distributed, but more restrictions follow
  2. we may have "weak dependency" (\\(X\_{i}, X\_{i+1}\\) are dependent, but \\(X\_i,X\_{i+10000}\\) is ind \\(\rightarrow\\) suitable version exists
- proofs
  - \\(X\sim \text{bino}\\) : not generalizes well
  - proof using MGF : TODO
- moderate \\(n=30\\) also works good
  - If \\(X\_i\\)s have __certain properties__, such as `symmetry`, `unimodality` then it helps (to reduce required, minimum \\(n\\))
- often used in stating \\[P(S\_n\leq a) \approx b \\\] which involves 3 params : \\(a, b, n\\)
  - often in a form __given two, find third__


### Examples

<img src="{{site.url}}/images/math/prob/normal_table.jpg" width="700">  

Example 1
- draw discrete uniform, convolve it \\(n\\) times

<img src="{{site.url}}/images/math/prob/clt_convolve.jpg" width="600">  


Example 2
- \\(X\_i : i.i.d \exp(1/2)\\) be weight of a package
- We load container with \\(n=100\\) weights
- \\(P(S\_n\geq 210)\\) ?
  - \\(\mu=\sigma=2\\), so that \\[P\left( \frac{S\_n-200}{20} \geq \frac{210 - 200}{20} \right)\\] \\[ P(Z\_n\geq 0.5) = 1 - \Phi(0.5\\]

Example 3
- same \\(X\_i\\). Now we want \\(P(S\_n\geq a)\\), choosing the __capacity__ \\(a\\) so that the probability that the weight of 100 packagess exceeds the capacity is 5%.

\\[0.05 \approx P\left( \frac{S\_n-200}{20} \geq \frac{a - 200}{20} \right) \\]
\\[\approx 1-\Phi(\frac{a-200}{20})\\]
\\[\Phi(1.645) = 0.95\\]


Example 4
- same \\(X\_i\\). Now given the capacity and probability, how many packages we must load, so that the probability that the sum of all packages exceeds capacity 210 is 0.05? \\[P(S\_n\geq 210) \approx 0.05\\]

\\[P\left( \frac{S\_n-2n}{2\sqrt{n}} \geq \frac{210 - 2n}{2\sqrt{n}} \right)\\]
\\[\approx 1-\Phi(\frac{210-2n}{2\sqrt{n}}) \approx 0.05\\]
\\[\frac{210-2n}{2\sqrt{n}} = 1.645\\]


Example 5
- same \\(X\_i\\)
- load container, until weight exceeds 210.  
  \\(N\\) = number of packages loaded
- \\(P(N>100)\\) ? 
- there is no way to apply CLT on \\(N\\). Instead we decompose it

\\[P(\sum\_{i=1}^{100}X\_i\leq 210)\\]
\\[\approx \Phi(\frac{210-200}{20}) = \Phi(0.5) = 0.6995\\]



`De Moivre-Laplace CLT to the binomial`
\\[P(S\_n=19) = P(18.5 \leq S\_n \leq 19.5)\\]
(1/2 correction)


### The Pollser's problem revisited
- previously, used Chevyshev. Now we use CLT and hope to get more accurate results

Let
- \\(p\\) be the fraction of population that will vote "yes" in a referendum
  - we want to estimate \\(p\\)
- Choose \\(i\\) th person uniformly, independently, and define a RV \\(X\_i\\) by
  \\[ X\_i=
  \begin{cases}
    1 & \text\{if yes,\} \cr
    0 & \text\{if no.\}
  \end{cases}  
  \\]
- we see that \\(E[X\_i] = p\\), \\(V[X\_i] = p(1-p)\\)
- \\(M\_n = (X\_1+...+X\_n)/n\\) : sample mean, fraction of "yes" in our sample. approximation to \\(p\\)
- we want "small error", e.g. \\(\|M\_n-p\| < 0.01\\)

We want to express
\\[P\left( \|M\_n-p\| \geq 0.01 \right)\\]
as the form of
\\[Z\_n=\frac{S\_n-n\mu}{\sqrt{n}\sigma}\\]

Now,
\\[P\left( \|M\_n-p\| \geq 0.01 \right)\\]
\\[ = P\left( \left\| \frac{S\_n-np}{n} \right\| \geq 0.01 \right)\\]
\\[ = P\left( \left\| \frac{S\_n-np}{\sqrt{n}\sigma} \right\| \geq \frac{0.01\sqrt{n}}{\sigma} \right)\\]
\\[ = P\left( \left\| Z\_n \right\| \geq \frac{0.01\sqrt{n}}{\sigma} \right)\\]

Note that \\(\\sigma = p(1-p) \leq 1/4\\), so that
\\[  P\left( \left\| Z\_n \right\| \geq \frac{0.01\sqrt{n}}{\sigma} \right) \leq P\left( \|Z\| \geq 0.02\sqrt{n} \right) = 2(1-\Phi(.02\sqrt{n}))\\]

ex) \\(n=10,000\\) : prov \\(\leq 2(1-\Phi(2)) = 2(10.9772) = 0.046\\)

"probability that we will get error over 0.01% is lower than 4%, if we collect 10,000 poles"

Other problem : what if we want prob that is lower than 0.05%?
\\[2(1-\Phi(.02\sqrt{n})) = 0.05\\]
\\[\Phi(.02\sqrt{n}) = 0.975\\]