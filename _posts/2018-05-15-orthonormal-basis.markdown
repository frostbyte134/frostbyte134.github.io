---
layout: post
title:  "Orthonormal basis, Gram-Schmidt and QR factorization"
date:   2018-05-15 18:16:00 +0900
categories: linear_algebra
use_math: true
tags: linear_algebra
---
A set of vectors \\(\{q_1,...,q_n\}\\) are orthonormal if
\\[q_i^Tq_j=
\begin{cases}
    0 & \text\{if \} i \neq j \cr
    1 & \text\{if \} i = j
\end{cases}
\\]
A matrix composed of orthonormal basis is generally denoted \\(Q\\).  
<h3 id="properties_of_orthonormal">Properties of Orthonormal matrix Q</h3>
{:.deccounter}
1. \\(Q^TQ=I\\).  
\\(\rightarrow\\) If \\(Q\in R^n\\) \\(Q^T\\) is a left inverse, and <a href = "{{site.url}}/linear_algebra/2018/05/10/left-inverse-is-the-right-inverse.html" target="_blank">thanks to the statements here</a>, \\(Q^T\\) is also a right inverse.
2. \\(\\| Qx\\| =\\| x\\| \\), since \\[{\\| Qx\\|}^2=x^TQ^TQx=x^Tx={\\| x\\|}^2\\]
Therefore, __multiplication by__ \\(Q\\) __preserves length.__
3. Every eigenvalues of \\(Q\\) has absolute value 1  
`proof`:
\\[\\|Qx\\|=\\|x\\| \quad\textrm\{and\}\quad Qx=\lambda x\\]
\\[\rightarrow \\|x\\|=\\|Qx\\|=\\|\lambda x\\|=\|\lambda\|\\|x\\|,\\]
4. __Eigenvectors__ corresponding to different eigenvalues __are orthogonal__.  
Let \\(Qx=\lambda_1x,Qx=\lambda_2x,\\>\lambda_1\neq\lambda_2.\\) Now by property 1, \\[x^Ty=(Ux)^T(Uy)=(\lambda_1x)^T(\lambda_2y)=\lambda_1\lambda_2x^Ty\\]Comparing each side we come to the conclusion that \\(\lambda_1\lambda_2=1\\) or \\(x^Ty=0\\).  
However, by the property `(2)` and the assumption that \\(\lambda_1\neq\lambda_2\\) we have \\(\lambda_1\lambda_2=-1\\), so that \\(x^Ty=0\\).
5. Product of two orthonormal matrices is orthonormal.
`proof`:  
Let \\(Q, S\\) be an arbitrary orthonormal matrix, so that \\(Q^\{-1\}=Q^T,\\>S^\{-1\}=S^T\\). Then
\\[(QS)^T=S^TQ^T=S^\{-1\}Q^\{-1\}=(QS)^\{-1\}.\\]
{:.deccounter}

<h3 id="ortho_basis">Orthonormal Basis</h3>
Finding coefficients of orthonormal basis is extremely simple.  
Let  \\(\{q_1,...,q_n\}\\) be an orthonormal basis in \\(R^n\\).  
Consider an arbitrary vector in \\(R^n,\\>b=c_1q_1+\cdots+c_nq_n\quad\rightarrow\quad Qc=b.\\)  
By multiplying \\(q_i\\) on both sides, \\[b^Tq_i=c_iq_i^Tq_i\quad\rightarrow\quad c_i=\frac\{b^Tq_i\}\{q_i^Tq_i\}=b^Tq_i\\]
and we have,
\\[b=q_1^Tbq_1+...+q_n^Tbq_n\\]
<a href="{{site.url}}/linear_algebra/2018/05/16/projection.html#one-dim-proj" target="_blank">Remember that</a>, \\(\frac\{a^Tb\}\{a^Ta\}\\) is the 1-dimensional projection of \\(b\\) onto the line spanned by \\(a\\). Thus we can interpret \\(c_i\\) as the projection of \\(b\\) on the line spanned by \\(q_i\\).  
If we have insufficient orthogonal vectors \\(\{q_1,...,q_r\},\\>r<n\\) then \\[Qx=b\\] mignt nit have an answer, and the problem indeed becomes projection.
\\[Q^TQ\hat\{x\}=Q^Tb\quad\rightarrow\quad \hat\{x\}=Q^Tb=
\begin\{bmatrix\}\{\}
q_1^Tb \cr \vdots \cr q_r^Tb
\end\{bmatrix\}
\\]
(Columns are independent, since they are orthonormal)  
so that, the projection \\(p=Q\hat\{x\}=QQ^Tb\\)  


<h3 id="gram_schmidt">The Gram-Schmidt process</h3>
>Gram-Schmidt process converts independent vectors into orthonormal vectors.

Let \\(a, b, c\\) be a set of independent vectors.
{:.acounter}
1. \\(q_1=a/\\|a\\|\\).  
Now \\(\\{q_1\\}\\) is orthonormal.
2. Let \\(B=b-(q_1^Tb)q_1.\\>(q_1^Tb)q_1\\) is a projection of \\(b\\) over \\(q_1\\).  
By subtracting projection \\((q_1^Tb)q_1\\) from its original \\(b\\), we are removing \\(q_1\\) component from \\(b\\), to make \\(q_1\\) and \\(B\\) orthogonal. Then we normalize \\(B\\) by \\(q_2=B/\\|B\\|\\).
<img src="{{site.url}}/images/math/linear_alg/gram_schmidt.png" width="800" class="center"/>  
Now \\(\\{q_1,\\>q_2\\}\\) is orthogonal.
3. Let \\(C=c-(q_1^Tc)q_1-(q_2^Tc)q_2\\). Again \\((q_1^Tc)q_1\\) and \\((q_2^Tc)q_2\\) are projection of \\(c\\) over \\(q_1\\) and \\(q_2\\), and we subtract projections from original to make \\(C\\) orthogonal to \\(q_1\\) and \\(q_2\\), then normalize by \\(q_3=C/\\|C\\|\\).  
Now \\(\\{q_1,\\>q_2,\\>q_3\\}\\) is orthogonal and we are done.
{:.acounter}
<h3 id="qr_fact">QR-factorization</h3>
QR-factorization is closely related to the process of Gram-Schmidt.  
Notice that in `(b)`, \\(b\\) can __completely__ be represented with orthonormal vectors \\(q_1\\) and \\(q_2\\).
\\[B=b-(q_1^Tb)q_1\\]
\\[\rightarrow b=B+(q_1^Tb)q_1=\\|B\\|q_2+(q_1^Tb)q_1.\\]
Finding the coefficients is simple, as <a href="#ortho_basis">described above</a>.
\\[b=q_1^Tbq_1+q_2^Tbq_2\\]
And vice versa for \\(c\\) (wrt \\(q_1,q_2,q_3\\)). Now We can repharse the Gram-Schmidt process with matrix multiplication.
\\[
\begin\{bmatrix\}\{\}
| & | & | \cr
a & b & c \cr
| & | & |
\end\{bmatrix\}=
\begin\{bmatrix\}\{\}
| & | & | \cr
q_1 & q_2 & q_3 \cr
| & | & |
\end\{bmatrix\}
\begin\{bmatrix\}\{\}
q_1^Ta & q_1^Tb & q_1^Tc \cr
 & q_2^Tb & q_2^Tc \cr
 &  & q_3^Tc
\end\{bmatrix\}
\\]
Then, we factorized \\(A\\) into 
* \\(Q\\) : `any` orthonormal basis matrix
* \\(R\\) : upper tringular matrix generated by the QR-factorization

<h3 id="unitray_mat">Unitary matrix</h3>
Based on the concept of <a href="{{site.url}}/linear_algebra/2018/05/18/complex-inner-prod.html#hermit_inner_prod" target="_blank">complex conjugate and Hermitian inner product,</a>  
We say that \\(U\in\mathbb\{C\}^\{n\times n\}\\) is unitary if \\[U^\{-1\}= U^* =\overline\{U\}^T.\\]
or in other words, \\[UU^* = U^*U =I.\\]
It has all of the <a href="#properties_of_orthonormal">above 5 properties of orthogonal matrix</a> in complex vector space.
