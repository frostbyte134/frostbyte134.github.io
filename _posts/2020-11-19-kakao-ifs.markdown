---
layout: post
title:  "kakao ifs"
date:   2020-11-18 05:04:00 +0900
categories: coding
use_math: true
tags: coding python
---


<a href="https://if.kakao.com/" target="_blank">https://if.kakao.com/</a>


### 개인화 "콘텐츠 푸시" 고도화 후기 (2020)
- <a href="https://if.kakao.com/session/93" target="_blank">https://if.kakao.com/session/93</a>
- 콘텐츠 선정 / 발송량 선정 / 선호도 예측 / 자동화


#### 문제정의, 설계
- `컨텐츠 푸시`의 이유 : 유저 활성화
  1. 활성화 1 : 비활성 유저 활성화 __(발표 주제)__
    - 유저에 대한 접근체널이 거의 푸시밖에 없다고 함
  2. 활성화 2 : 기존 유저 활성화
    - 푸시 이외에 다른 체널이 있다고 함
- 활성화 상태 : 주1회 이상 접속
- `WAU` : weekly active user, 주간활성유저

비활성 유저
- 푸시 클릭율이 떨어짐
- `누구나 좋아할 만한 컨텐츠` (?) 추천이 일단 좋긴 함
  - 빅이슈 (정상회담), 경사
  - __흔하지 않다고 함__ (희소하므로 좋은 것)
  - 여기에 의존적이지 않은 푸시가 필요

> 목표 : 누구나 좋아할 콘텐츠를 보냈을 떄와 같은 수준의 WAU달성


#### 문제해결

전략, 목표
- 유저별 푸시는 주1회로 제한
- WAU수치 자체를 직접 최적화하긴 어려움
  - __대리 지표__ 사용 (proxy metric)
  - `클릭율 개선치` : 현재 컨텐츠 푸시 클릭율 / 대상 유저들의 평소 푸시 클릭율
    - 클릭율이 낮은 유저들이  클릭했을 시 높아짐
    - 목표 수치 : 2.4 (평소 클릭율 대비 2.4배 증가)
- 전략 : 개인화

__자동화 푸시 시스템__ : 컨텐츠 선정 \\(\rightarrow\\) 개인화 선호도 예측 \\(\rightarrow\\) 발송량 설정/발송 \\(\rightarrow\\) 결과 분석 \\(\rightarrow\\) 처음으로
1. 컨텐츠 선정
  - 컨텐츠 생성 30분후 푸시 발송여부 판단
  - 제목 + 본문 기반 모델링
  - `gradient boosting` ?
  - 컨텐츠 별로 발송량을 설정함? (200~300?) 유저가 기준이 되어야 하는 것 아닌가? 
  - 제목 자동 설정 : 템플릿 기반, A/B테스팅을 통해 결정
2. 개인화 선호도 예측
  -  각 컨텐츠별로 발송량 내에서, 선호도가 높은 유저에게 보냄
  -  content based (word embedding)
  -  `CTR` (click through rate) prediction
     -  과거 클릭 모델링. collab filtering 인듯
  - looklike
    - '해당 컨텐츠에 대한 선호가 확실하게 판단되는 유저군과 유사한 유저군을 찾는 방식'
    - 유저 기반 nearest neighbor?
3. 컨텐츠의 발송량 설정 (__재발송이 성능 향상에 기여가 컸다고 함__)
  - __처음에는 소량,__ 유저반응 확인 (클릭율 개선치), 좋으면 발송량 늘림 (`feedback loop`)
    - 컨텐츠가 시즌성(?)이 강함 : `temporal dynamic`이 큰 듯. 따라서 처음에 일부 유저만 대상으로 소량만 보냄
    - 목표치보다 낮아도, 신뢰구간 안에 목표치가 들어오면 다시 보내본다고 함
    - 신뢰구간 : 정규분포 cdf 사용 (central limit theorem)
4. 기타 이슈
  - 비활성 유저들의 모델링이 어려움
  - 푸시 피드백 속도가 느림
  - 컨텐츠 수명이 짧음 (뉴스 라이프사이클 = 3~4시간)


### Buffalo (2019)
- `matrix factorization`
- priority: scalability가 최우선 (만족X시 적용자체가 불가능), 성능이 그 다음이었다고 함
- __최적화된 Python/C++ 코드베이스와 병렬처리를 효과적으로 구현__
  - python/c++ : gil처리는 Cython의 nogil context로만?
  - openMP의 dynamic scheduling이외에 개선점?
- 기본적으로 sparse matrix대응이 되어있다고 함. sparse mat 행렬곱을 못 본거 같은데..못찾았거나 라이브러리에서 해 주는 건가?



### 둥꿍둥꿍 느낌 아는 음악 바텐더 (2019)
- VGG-like feature extractor (음악을 퓨리에변환한 것을 자른 `mel-spectrogram` (?) - 감성tag predict)는 크게 좋지는 않았다고 함
- matrix factorization
- 선택한 곡 목록 (playlist?) 기반 autoencoder - feature vector추출
  - `denosing` autoencoder
  - + tag output header
- cosine 유사도까지 봄


### 추천 시스템 맥락과 취향 사이 (2020)


### python application server for recommender system
- <a href="https://www.youtube.com/watch?v=6oOQJtLa14U" target="_blank">https://www.youtube.com/watch?v=6oOQJtLa14U</a>
- <a href="https://www2.slideshare.net/kimkwangseop/pycon-korea-2018-python-application-server-for-recommender-system" target="_blank">https://www2.slideshare.net/kimkwangseop/pycon-korea-2018-python-application-server-for-recommender-system</a>


Intro
- 추천 시스템 = 데이터를 소비하는 새로운 경험?
- 추천 : 아이템 추천 / 개인화 추천 (시스템적으로 크게 다르지 않음)
  - 아이템 추천 시나리오 : 쿼리 \\(\rightarrow\\) 유사도 정렬 \\(\rightarrow\\) 메타데이터/선호도 조회 \\(\rightarrow\\) 필터링 (개인선호도 / 재고 등의 temporal) \\(\rightarrow\\) 추천
    - 필요한 것 : 개인의 활동 정보, 관계/유사도, 상품정보


APP 서버를 파이썬으로 (schema(rule) 기반 추천 제공)
- 룰/명세 기반으로 동작하는 파이썬 서버
- 요구사항 : 3가지 영역
  1. DB (유사도/메타데이터/이력 데이터) : 수평확장, 대량의 R/W (nosql)
  2. `OLTP` : Online Transaction Processing. 관계형 분석 기능 (where절, join 등?)
  3. 실시간 분석 (includes personalized recommendation), 복잡한 비즈니스 로직?
- 실시간 분석 / OLTP 최적화가 목표
  - 관계형 DB로 처리하기 미묘한 작업들 _(ex - 제외가 아니고 우선순위를 뒤로 밀어내기)_, 대용량/실시간 학습 대응
  - 다른 서비스가 사용하기 쉽게 API로 만들어야 한다고 함

> 개인화 추천을 미리 계산하는 것은 비효율적, 실시간 분석이 적합 (사용자=수천만, 아이템=수백만)

#### Arch
<img src="{{site.url}}/images/recomm/brunch_recomm_arch.jpg" width="700">

- 각 container당 4개정도의 python procs
- 새로운 서비스 = 스키마 추가 (생산성)
  

#### 개발 후기
Python2 Tornado vs python3 Sanic
  - Tornado legacy가 있었지만 3 Sanic 선택
  - 코드 가독성, 양이 줄음
  - Tornado는 low lvl로 내려가기 쉽지만 코드가 비교적 복잡하다고 함
  - Tornado : raise로 리턴? 
  - Sanic의 uvloop (이벤트 루프)가 좋은 이벤트 루프라고 함
- `asyncio.Future`
  - 단일 함수 내에서 순차적 await - 다른 함수와의 비동기 연산은 되지만 현재 함수에서의 병렬화는 안됨. 어차피 IO연산들 (uninterruptible sleep) 이라면 future로 단일 함수 내부에서도 병렬로 실행하는 것이 좋음

********************************

DB profiling
  - 대부분의 시간이 network IO였다고 함
  - DB 프로파일링 결과
    1. MongoDB의 aggregating : 여러 연산의 sequential 실행  
        - filter연산은 App 서버에서 하는 것 보단 DB단에서 하는 것이 좋음
        - DB에서 group by는 엄청 느렸는데 app서버에서가 훨씬 빨랐다고 함
        - DB를 너무 믿지 말자

********************************

caching
  - db조회 비용이 비싸서 캐시 hit을 최대화
  - 쿼리도 쪼개서 가능한 cache hit을 높임
  - redis 1 : python instances N
    - 프로세스간의 중복 요청도 cache로 처리 가능
  - 슈퍼노드 이슈 (?)
    - DB는 shard를 만들어 데이터를 쪼개서 저장
    - `적절한 키로 샤드를 구성하더라도, 공통되어 사용되는 리소스가 존재하는 경우 특정 샤드에 부하가 집중된다고 함`
      - 핫한 아이템이 있는 경우,
    - 인스턴스 내에서 공용 캐쉬 (python instances N개 내에서 공유)를 써서 어느정도 대응이 되었다고 (caching) 함 
- 커스텀 필터 구현 (DB?)
- 룰에 파이썬 코드를 심고 런타임 컴파일(?) 을 사용 (처음부터 배포하는 것 보단) 
  - `@filter : lambda x : x.lower(10)` 같은걸 받으면 eval해서 적용한 건가? ㄷㄷ
- 버킷 테스트?

********************************

설정 재배포
1. 모든 proc을 동시에 재시작 (안좋음)
2. 1개씩 PID 찝어서 재시작
3. WSGI 를 쓰는 장점?
    - `GUNICON` 에 kill sigterm - 알아서 graceful shutdown을 시켜준다고 함
      - 각 인스턴스마다 떠 있는 gunicon에 signal만 보내주면 된다고 함
      - 문서의 `Signal Handling` 부분에 Graceful shotdown

********************************

CPU연산
- Numpy, Scipy : openblas, sims 등을 사용한 컴파일까지 하면 C코드랑 큰 차이가 없다고 함


이벤트루프 상에서 스위칭 시 memcpy가 발생하는 경우?
- 큐를 사용했을 시
  - 프로듀서 : 컨슈머가 다른 상황에서 발생한다고 함
  - 프로세스가 달랐으면 IPC를 통해서 데이터 카피가 일어난다고 함

`failover` (?) 첨들어봄
- DB의 failover는 몽고디비의 failover를 따라감
- Instance 내의 failover / nginx