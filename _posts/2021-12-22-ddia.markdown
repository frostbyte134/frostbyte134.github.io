---
layout: post
title:  "Designing Data Centric Application"
date:   2021-12-22 08:00:05 +0800
categories: coding
use_math: true
tags: coding
---


> Kleppmann, Martin. Designing Data-Intensive Applications . O'Reilly Media. Kindle Edition. 


__하루에 1챕터씩 읽기!!!!__

### Chap 1

`Data-intensive` app
- RAW cpu power is rarely a limiting factor
- db, cache, search index, stream/batch processing


#### 3 concerns in software systems
1. `Reliability`
  - Should continue to work `correctly` (performing the correct function at the desired lvl of performance) in the face of `adversity` 
 (hw/sw/human faults)
  - `fault`: system component fails / `failure`: system as a whole fails
  - must be fault-tolerant / resilient
  - HW failure: often add redundancy to individual HW
  - 휴먼에러: 잘못쓰기 어렵게 만들기, easy rollback, monitoring
2.  `Scalability`
  - reasonable way to dealing with the system growth
  - describe the __load__ of system (ex - TPS, hit ratio of cache, DAU, ...)

#### 트위터 타임라인 구성하기
- 트윗은 글로벌하게 그냥 저장
- 트윗이 올라왔을 때 타임라인 구성하기
   1. 온디멘드 타임라인 구성 
   2. 유저 A의 트윗이 올라오면, 해당 유저 팔로워의 미리 만들어 놓은 타임라인 증분 업데이트
- 처음 1번에서 2번으로 전환했다 함 (read operation이 훨 많아서)
  - 이 경우, 핵심 load parameter는 fan out 숫자임
- 최종적으로, 2번이나 핵심 유저가 트윗 올리면 바로 증분업데이트 안하고 (팬아웃이 너무 많아 로드 파라미터를 너무 크게 올림), 타임라인 올릴 때 유명 유저 리스트만 훑는다고 함

Latency and response time
- `latency`: dutation that a request is waiting to be handled  
- `response time`: 클라이언트 기준 응답시간 (서비스 타임)

#### `Maintainability`
  - productivity (even with many ppl working with)
  - fixing bugs, keeping system opetational, investigating failures, ...

3 design principle for SW systems (for high maintainability)
- Operability (easy to operate)
  - Good operatibility means making routine tasks easy
- simplicity (easy to understand)
- evolvability (easy to make change)
  - agile, tdd, short cycles, refactor

#### Describing Performance
- SLA, P50, P95, P99 (tail lavencies), avg
- five-nine
- Amazon has observed 100ms increase in response time reduces sales by 1%
- 1sec slowdown reduces a customer satisfaction by 16%
- OTOH, optimizing extreme tail performance is too expensive (over engineering)
- calculating average - window selection and alg is important (`forward decay`, `t-digest`, `HdrHistogram`)


#### Approahes for coping with Load
- scale up (HW up) / scale out (병렬처리)
- `elastic` system: can automatically add computing resources when they detect a load increase

> While distributing stateless services across multiple machines is fairly straightforward, taking stateful data systems from a single node to a distributed setup can introduce a lot of additional complexity. For this reqson, common wisdom until recently was to kkep your database on a single node (scale up) until scaling cost or HA requirements forced you to make it distributed



#### ACID
- RDB: ACID 지원
- noSQL: 어떤지?
- redis: 싱글쓰레드인데 파이프라이닝이 있음 (이거 명확하게 정리 좀...)


### Chap 2
대부분의 APP은 여러 데이터 모델 (=레이어)로 이루어져 있음
- 로우레벨 (임베디드) / 디비 / APP단 등
- every data model embodies assumptions about how it is going to be used

#### Relational vs Document model
SQL
- Data is organized into `relations` (called `tables` in SQL), where each relation is an unordered collection of `tuples` (`rows` in SQL)
- transation기능을 60~70년대부터 추가하며 계속 쓰임
- other databases at that time forced app devs to think about the internal repr of the data in the DB. The goal of the relational model was to hide that impl details behind a (cleaner) interface
  - 70~80년대에는 network / hierarchical model 등이 있었으나, 사라짐 (위와 같은 이유 때문이었을 듯)

NOSQL
- > The name `NoSQL` is unfortunate, since it doesn't actually refer to any particular tech (catchy Twitter hashtag for a meetup on opensource, distributed, non-relational dbs in 2009)
- scalability, opensource, non-relational (too restrictive)

#### Object-Relational Mismatch
OOP + Relational의 부조화인듯?
- If data is stored in relational tables, an awkward translation layer (ORM, SqlAlchemy!) is required between the objects in the app code and the db model of tables, rows, and cols
 - `impedence mismatch` problem

#### One-To-Many
- ex) 사람은 평생 여러 경력, 여러 교육을 받음
- 이게 impedence mismatch 문제하고 무슨 관계지. 지금은 잘 모르겠음
- SQL: 테이블을 쪼개고 foreign key ref를 걸음
- noSQL, 특히 document db: 기본적으로 트리 형태 (one-to-many)를 쉽게 저장할 수 있음. 다소의 중복은 있지만...
  - ex) human json obj안에 edu, career json obj
  - 결국 join을 안해도 되므로, 이렇게 로컬에 (다소에 데이터 중복저장을 감안하고) 관계있는 데이터를 다 가지고 있는 경우를 locality가 있다고 하는 듯

#### Many-to-One, Many-to-Many
- many-to-one: 지역 1개에 여러 사람이 살고 있음
- many-to-many: 기업에 있는 출신 학교? 약간 user를 통해 transitive하게 정의되는 관계인 듯
- SQL: join. 안쓰고 컬럼을 (중복해서) 더 잡아도 되는데 consistency를 알아서 관리해야 함
- noSQL: 조인을 알아서 app단에서 처리해야 함
  - 예전 network model에선, 비슷하게 트리형태로 데이터를 저장했긴 한데 관계있는 다른 데이터에 대한 포인터도 저장했다고 함 - 관리가 어려워 폐기 (데이터 모델 변경 시 너무 피곤해짐)

데이터가 트리형태일 땐 역시 noSQL이 나음. sql식의 테이블 쪼개기는 many-to-many도 비교적 대응가능한 반면 이런 상황에서 깔끔하지는 않음.
- 반면 many-to-many + join필요 = sql이 나음

#### Schema flexibility in Document Model
- nosql: schemaless (X) / `schema-on-read` (O, ~runtime type checking)
  - implicit schema가 있으나 enforced되지는 않음. 반면 sql은 `schema-on-write` (~compile-time type check) 임
- mysql같은 경우, alter table 할 경우 모든 데이터를 다 복사한다고 함 - leads to few secs of downtime

#### Query language for Data
- imperative: 수행방법까지 구체적으로 지시
  - 예전 db들 중에는 이런 식도 있었다 함
- declarative: 원하는 결과만 명시. optimization은 알아서 (SQL)
  - limited functionality, automatic optimization, low chance of mistake

mapreduce: 윗 둘 중간에 있음
- 몽고디비도 원랜 없었는데 json representation타입의 declarative인 `aggregation pipeline`을 도입했다고 함
  - > The moral of the story is that n NoSQL system may find itself accidentally reinventing SQL, albeit in disguise

그래프는 지금 관심이 없어서 스킵!


### Chap 3. Storage and Retrieval

어떻게 데이터를 무슨 포멧으로 저장하고 (`data model`) 어떻게 찾을 것인지 (`query language`) - chap2는 사용자 (개발자) 관점, chap3은 디비 관점
- 우선 `log-structured storage engines` / `page-oriented storage engines` (ex - B-tree)

Many databases internally use a log, which is an append-only data file.
- in this book, `log` refers to an append-only sequence of records. It doesn't have to be readable

In order to efficiently find the value for a particular key in the db, we need a different data structure: an `index`
- 보통 추가적인 메타데이터로 구성
- well chosen indexes speed up read queries, but every index slows down writes.
  - for this reasen db dont usually index everything by default, but require you to choose indexes manually

#### append only log + hash table index
- assumes KV storage
- 인덱스는 해시테이블: 메모리에 있음, 최근 key의 디스크 상 위치 저장
- compation: merge + append (overrite안함)
- deleting: 레코드에 `tombstone`남겨놓음. merging시 해당 record 이전 데이터들은 전부 무시
- partially written records: `Bitcask`는 첵섬으로 확인
- concurrency control: one writer thread (write이 sequential 하므로, concurrency로 얻는 이득이 별로 없는 듯)
- crash recovery: 파일을 전부 읽어도 되지만, `Bitcask`는 해시테이블 스냅샷 활용

append-only log의 장점
- merge가 sequential (random rw 필요없음)
- concurrency / crash recovery관점에서, overwrite하는 중 터질 일이 없음 (append하다 터지는 경우는 있겠지만)

hash table의 단점
- 파일에 넣기 어려움 (random access가 항상 필요)
- range queries are not efficient

#### SSTable
sorted string table
- segment (compaction의 단위) 내에서는 정렬 속성 유지
  - 이제 그냥 append를 바로 할 수 없음
- merging is simple and efficient: K-way merge
  - merge시 충돌 - segment간 시간 우선순위가 있으므로, 제일 최신 segment의 데이터만 유지하면 됨
- (해시테이블과 달리) 이제 키 하나를 찾기 위해 전체 키가 메모리에 없어도 됨. 일부 sparse key만 있으면 위치를 빠르게 찾을 수 있음
  - 키를 구역으로 나누고, 각 구역의 시작데이터만 메모리에 올리고, 각 구역은 압축해서 저장해도 됨
  - besides saving dist space, compression also reduces the I/O bandwidth use (!)

Constructing and Maintaining SSTables
- 결국 구성할땐 random access가 많으므로, 메모리에서 하는 게 효율적
- 메모리에서 AVL/RB tree 구성 (`memtable`!)
  - 크기가 일정 이상 커지면 디스크에 저장: 대부분 트리들은 노드 순회 방법 제공하므로 그대로 쓰면 sstable file이 됨
  - 써지는 동안 들어오는 write은 새로운 memtable에
- 키가 memtable없으면, 최신 순서대로 sstable 파일 찾음
- 가끔씩 bg에서 merging / compation 수행
- crash시 memtable은 유실됨: append only log를 복원용으로만 저장. memtable이 sstable이 되면 해당 로그도 폐기 가능 (크기가 크지 않음)
- rocksDB / levelDB. 구글의 Bigtable paper에 sstable / memtable 용어가 도임됬다 함. cassandra, hbase에서도 해당 방법 사용

#### Making an LSM-tree out of SSTable

